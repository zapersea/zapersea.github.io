<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="牧羊人小站">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="牧羊人小站">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="牧羊人小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>牧羊人小站</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">牧羊人小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/31/【夕花朝食】丁酉晚钟/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/31/【夕花朝食】丁酉晚钟/" itemprop="url">丁酉晚钟</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-31T23:53:23+08:00">
                2017-12-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/夕花朝食/" itemprop="url" rel="index">
                    <span itemprop="name">夕花朝食</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>又是一年，再次站在大悦城旁的天桥前，一样的时间一样的钟声，内心毅然涌起各种的思绪。丁酉年就这么过去了，乍一想是那么的快，那么的突然；再想想，倒是能想起很多很多，这一年大概也不是那么容易吧。经历过迷惘，经历过选择，有过不少悠然的时刻，也有过不少心累的时刻。闭上眼睛，能看见那个跌跌撞撞的自己一步一步蹒跚往前走，再睁开，眼角甚至不争气的湿润了一些。</p>
<p>春风拂面的时节，忘不了的是那个喧闹的惠新西街南口站。睡眼惺忪的自己，饿着肚子，跨域整个北京城；从西北角到东南角，3条地铁换乘，每天4个小时的往返；虽然每天都很累，但总会给自己一种自己至少很努力的感觉，大概这样就已经足够了吧。公司的食堂有着各种美味，虽然那是不觉得，之后辗转各处缺有了强烈的这种感觉。大概人都是对现在所拥有的感受不强，失去后才俞来俞想念。朝阳星辰交替的这条线路上也有着我对北京最美的记忆，在某个不知名的地铁站附近，那一片美不胜收的樱花树，看的那些霎那间，所有疲惫都那么值得了。</p>
<p>北京的夏天还是那么热，结束实习，回到学校准备考试，图书馆成了我的依赖之地。不是因为别的，只是贪图那里面空调带来的清凉。大概自己就是那么怕热吧，从小便如此。高中时候冬天毫无顾忌的光手疯狂刷题，南方的冬天随很凌冽却没什么令我后怕的。夏天却永远离不开风扇空调，热会侵蚀我的思绪，一点一点。每天往返图书馆的日子很无聊，准备新实习面试，努力补各种理论知识。由于中途回家一段时间的原因，cs231的课拖到7月初才 finish，毕竟在家的自己是永远不可能学习的- - 学习新知识总是有一种不可名状的美，枯燥之后喝的水都更加美味，坐累的起来走几步都觉得务必舒畅。图书馆，空调，书，cs231，deep learning，这大概就是自己对北京夏天的记忆了吧。</p>
<p>金秋，是收获的季节。对我来说却又那么多意外与惊喜。很幸运能在一家自己很喜欢的公司，做这自己很喜欢的事，学着自己感兴趣的东西，虽然只有一个月。还记得公司前台那几个丑萌丑萌的公仔，还记得公司休息室每天不限量的零食与下午1点30的水果(就记得吃的了，笑)。每天晚上回去，回想一天总会觉得自己又学到了不少东西。那时候就会很开心的想，啊，大概这就是做自己喜欢的事的感觉吧。意外总是不期而至，一个月后忽然就就接到 了MSRA 的 offer。在揪心的抉择之后，还是觉得或许应该去更大的平台试试，毕竟这样的机会下一次也许就没有了。北京的十月，永远是充满喜悦与惆怅的。</p>
<p>最后三个月便是无止境的终日与工作相伴，很累很累。有时半夜回来，抬头看看天上冰冷的圆月，自己对自己苦笑说，我也是见过凌晨2点的北京了。实习的方向和自己的兴趣有一些不 match，欣慰的是真的可以学到大量的知识。最近一个月几乎每天都是11点后回，0点之后也不再奇怪，逐渐有了腰酸背痛的毛病。最后下决心办了张健身卡，开始锻炼之路，令人惊喜的是，坚持锻炼之后确实不会那么经常的出现身体不适了。</p>
<p>到明天就真正24了，本命年或许应该对自己多一些期望，多一些目标吧。但真要列出来之时却又那么难以逐一数落，就简单说说吧。</p>
<p>再努力一点学习，努力提升一下自己，少吃一点垃圾食品，多健一些身，成熟一点，好好找工作，找好工作。嗯，这就是全部了，加油吧！</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/19/Mac-使用rar和unrar指令/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/19/Mac-使用rar和unrar指令/" itemprop="url">Mac 使用rar和unrar指令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-19T21:49:39+08:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/备忘/" itemprop="url" rel="index">
                    <span itemprop="name">备忘</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>下载<a href="http://note.youdao.com/" target="_blank" rel="external">RAR工具包</a>，下mac的包</li>
<li>从终端进入到解压文件夹rar，里面是刚才下载的文件</li>
<li>执行两条指令</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo install -c -o $USER rar /usr/local/bin/</div><div class="line"></div><div class="line">sudo install -c -o $USER unrar /usr/local/bin</div></pre></td></tr></table></figure>
<ul>
<li>测试</li>
</ul>
<p>压缩文件A和B：rar a read.rar A B</p>
<p><img src="http://ws3.sinaimg.cn/large/005CRBrHly1g2kidmoc0uj30zq0aeta6.jpg" alt="83984158"></p>
<p>解压：unrar x read.rar</p>
<p><img src="http://wx1.sinaimg.cn/large/005CRBrHly1g2kidvy1ghj30yk0fc0vx.jpg" alt="83983382"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/19/【论文笔记】Attention-Is-All-You-Need/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/19/【论文笔记】Attention-Is-All-You-Need/" itemprop="url">【论文笔记】Attention Is All You Need</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-19T21:49:07+08:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/水滴石穿/" itemprop="url" rel="index">
                    <span itemprop="name">水滴石穿</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>摘抄就不写了，有很多现成的可以参考，这里挑一些点写一下自己的理解。</p>
<p>整体结构如下<br><img src="http://ws1.sinaimg.cn/large/005CRBrHly1g2kjb8i9dqj31cs0xudmj.jpg" alt="46270443"></p>
<h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><p>paper中说主要提出了两种attention，Scaled Dot-Product和 Multi-Head 。其中scaled这个就是基本的点乘attention，区别在于它加了一个对维度的scale。</p>
<p><img src="http://wx4.sinaimg.cn/large/005CRBrHly1g2kjbh0lmzj31ai0iqgpy.jpg" alt="81012683"></p>
<p>之所以对点乘值除以一个根号dk，作者是说当Q和K的维度dk太大的时候，点乘的值也变得巨大，这样会使得softmax函数的梯度变得特别特别小。</p>
<blockquote>
<p>We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4. To counteract this effect, we scale the dot products by 1/sqrt(dk).</p>
</blockquote>
<p>对于点乘的函数，我是这么理解的。。。<br><img src="http://wx4.sinaimg.cn/large/005CRBrHly1g2kjcnq7r8j312603eglv.jpg" alt="5755345"></p>
<pre><code>Qi 和 Vi都是k维，所以假设都是 1xk ,Q一共有n个，(K,V)一共有m对

Q dot KT分解为
[ Q1 ]                       [Q1*K1, Q1*K2...Q1*Km]    [ W1 ]
[ Q2 ]  dot [ K1,K2...Km] =  [Q2*K1, Q2*K2...Q2*Km]  = [ W2 ] 
  ...                             ........              ...
[ Qn ]                       [Qn*K1, Qn*K2...Qn*Km]    [ Wn ]

对应 (n,k)dot(k,m) = (n,m)
进过softmax之后，每一行代表一个权重信息Wi ,n行代表n个query各自取value时候的权重


[ W1 ]       [ V1 ]
[ W2 ]  dot  [ V2 ]
 ...          ...
[ Wn ]       [ Vm ]

对应 (n,m)dot(m,v) = (n,v)
n行对应n个query，从而每个query最终得到一个weighted的value，还是保持v维
</code></pre><p>总之，最后每个query有一个weighted value， dv维</p>
<h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><p>这里设定的，原始Q,K,V的维度都等于d-model</p>
<p>基本思想就是分治，将Q，K，V全部分成h等份，每一份(dk=dv=dmodel/h)分别在linear变换后进入一个attention function ，得到的结果concate连接，再进过一个linear变换，得到最终结果。作者说这样的好处是可以充分让encoder-decoder的不同位置，通过不同的linear，体现出更丰富的结果</p>
<blockquote>
<p>Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions</p>
</blockquote>
<p>函数如下</p>
<p><img src="http://wx2.sinaimg.cn/large/005CRBrHly1g2kjdrtmitj316o048js2.jpg" alt="94634163"></p>
<p>这里面Q Wi，对应(n, dmodel) dot (dmodel,dk) = (n ,dk)</p>
<p>就是对Q做第i个linear变换，把它从dmodel维变成dk维,其实就是取Q的第i部分。K和V类似理解就好。</p>
<p>h份attention 函数parallel进行，每一份得到的结果也是 dv=dmodel/h,concate起来就又是dmodel维度了。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/19/【caffe源码学习】l2-normalize-layer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/19/【caffe源码学习】l2-normalize-layer/" itemprop="url">【caffe源码学习】l2_normalize_layer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-19T21:49:01+08:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Caffe/" itemprop="url" rel="index">
                    <span itemprop="name">Caffe</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>参考的l2_normalize_layer来自<a href="https://github.com/gy20073/compact_bilinear_pooling" target="_blank" rel="external">Compact Bilinear Pooling</a></p>
</blockquote>
<p>先看一下hpp文件</p>
<h4 id="l2-normalize-layer-hpp"><a href="#l2-normalize-layer-hpp" class="headerlink" title="l2_normalize_layer.hpp"></a>l2_normalize_layer.hpp</h4><p>C++ hpp文件高亮支持一般，这里我就索性用截图了</p>
<p><img src="http://ws4.sinaimg.cn/large/005CRBrHly1g2kjfhy2hbj311e13aait.jpg" alt="51568918"></p>
<p>除了常规的cpu，gpu前向后向传播，还定义了一个叫<code>squared_</code>的Blob，用来存bottom的平方。top和bottom的blob都只有一个，类型名是<code>L2Normalize</code>。</p>
<h4 id="l2-normalize-layer"><a href="#l2-normalize-layer" class="headerlink" title="l2_normalize_layer"></a>l2_normalize_layer</h4><h4 id="Reshape"><a href="#Reshape" class="headerlink" title="Reshape"></a>Reshape</h4><p><img src="http://ws1.sinaimg.cn/large/005CRBrHly1g2kjg663jpj30yq08utas.jpg" alt="23341806"></p>
<p>把top 和 squared这两reshape成bottom的shape，[num,channel,height,width] 对应N <em> C</em> H * W</p>
<h4 id="Forward-cpu"><a href="#Forward-cpu" class="headerlink" title="Forward_cpu"></a>Forward_cpu</h4><p><img src="http://ws4.sinaimg.cn/large/005CRBrHly1g2kjghpefzj30x00egtcc.jpg" alt="80278970"></p>
<p>取bottom的数据到bottom_data, top和squared的数据都设为mutable待求。n是batch size N，d是dim，按照caffe的惯例还是等于<code>C * H * W</code>。</p>
<p>令squared等于bottom对应element值的平方，然后进入一个n循环，以样本为单位进行操作。每次循环取squared的样本下面长为d的全部元素和(即bottom的平方和)，存到normsqr。然后每个bottom的每个元素除以normsqr的根号，赋值给top。</p>
<p>从而实现L2前向，<code>top[i] = bottom[i] / sqrt ( sum(bottom[j]*bottom[j]) )</code></p>
<p>用到的函数</p>
<ul>
<li><p><code>void caffe_sqr&lt;float&gt;(const int n, const float* a, float* y)</code>     </p>
<p>  对应element_wise操作， y = a^2 ，注意是平方不是平方根。这里是 <code>squared_data = bottom_data * bottom_data</code></p>
</li>
<li><p><code>float caffe_cpu_asum&lt;float&gt;(const int n, const float* x)</code></p>
<p>  计算 vector x 的所有element的绝对值之和。这是是取squared_data的长度为<code>C * H * W</code>的元素和。</p>
</li>
<li><p><code>void caffe_cpu_scale&lt;float&gt;(const int n, const float alpha, const float *x,float* y)</code></p>
<p> 计算<code>y = alpha*x</code>，在这里 <code>top_data = pow(normsqr,-0.5)*bottom_data = bottom_data/pow(normsqr,0.5)</code>，而pow(normsqr,0.5)可以理解为bottom的平方和开根号。</p>
</li>
</ul>
<h4 id="Backward-cpu"><a href="#Backward-cpu" class="headerlink" title="Backward_cpu"></a>Backward_cpu</h4><p><img src="http://ws1.sinaimg.cn/large/005CRBrHly1g2kjgxd83ij30ys0hawiz.jpg" alt="59837972"></p>
<p>L2梯度的推导没怎么找到。。。</p>
<p>取top的data和diff，取bottom的data，bottom的diff设为mutable待求。n等于batch size N，d等于dim为<code>C* H * W</code>。</p>
<p>接下来还是n循环分样本做。</p>
<pre><code>a = top_data dot top_diff  ,内积得到一个数值
bottom_diff = a * top_data
bottom_diff = top_diff - bottom_diff
a = bottom_data dot bottom_data
bottom_diff = pow(a,-0.5) * bottom_diff
            = bottom_diff / pow(a,0.5)
</code></pre><p>用到的函数</p>
<ul>
<li><p><code>Dtype caffe_cpu_dot(const int n, const Dtype* x, const Dtype* y)</code></p>
<p>  返回x与y的内积，这里是top_data*top_diff ，返回一个数值</p>
</li>
<li><p><code>void caffe_sub&lt;float&gt;(const int n, const float* a, const float* b, float* y)</code></p>
<p>  实现element-wise的减 , y[i] = a[i] - b[i] 。这里是 bottom_diff = top_diff - bottom_diff。</p>
</li>
</ul>
<p>附完整代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layer.hpp"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/l2_normalize_layer.hpp"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/math_functions.hpp"</span></span></div><div class="line"></div><div class="line"><span class="keyword">namespace</span> caffe &#123;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> L2NormalizeLayer&lt;Dtype&gt;::Reshape(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class="line">  CHECK(top[<span class="number">0</span>] != bottom[<span class="number">0</span>]) &lt;&lt; <span class="string">"do not support in place operation"</span>;</div><div class="line"></div><div class="line">  top[<span class="number">0</span>]-&gt;Reshape(bottom[<span class="number">0</span>]-&gt;num(), bottom[<span class="number">0</span>]-&gt;channels(),</div><div class="line">      bottom[<span class="number">0</span>]-&gt;height(), bottom[<span class="number">0</span>]-&gt;width());</div><div class="line">  squared_.Reshape(bottom[<span class="number">0</span>]-&gt;num(), bottom[<span class="number">0</span>]-&gt;channels(),</div><div class="line">    bottom[<span class="number">0</span>]-&gt;height(), bottom[<span class="number">0</span>]-&gt;width());</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> L2NormalizeLayer&lt;Dtype&gt;::Forward_cpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();</div><div class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_cpu_data();</div><div class="line">  Dtype* squared_data = squared_.mutable_cpu_data();</div><div class="line">  <span class="keyword">int</span> n = bottom[<span class="number">0</span>]-&gt;num();</div><div class="line">  <span class="keyword">int</span> d = bottom[<span class="number">0</span>]-&gt;count() / n;</div><div class="line">  caffe_sqr&lt;Dtype&gt;(n*d, bottom_data, squared_data);</div><div class="line">  Dtype epsilon = <span class="number">0.0000001</span>;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</div><div class="line">    Dtype normsqr = caffe_cpu_asum&lt;Dtype&gt;(d, squared_data+i*d);</div><div class="line">    caffe_cpu_scale&lt;Dtype&gt;(d, <span class="built_in">pow</span>(normsqr + epsilon, <span class="number">-0.5</span>),</div><div class="line">            bottom_data+i*d, top_data+i*d);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> L2NormalizeLayer&lt;Dtype&gt;::Backward_cpu(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div><div class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;</div><div class="line">  <span class="keyword">const</span> Dtype* top_diff = top[<span class="number">0</span>]-&gt;cpu_diff();</div><div class="line">  <span class="keyword">const</span> Dtype* top_data = top[<span class="number">0</span>]-&gt;cpu_data();</div><div class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;cpu_data();</div><div class="line">  Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_cpu_diff();</div><div class="line">  <span class="keyword">int</span> n = top[<span class="number">0</span>]-&gt;num();</div><div class="line">  <span class="keyword">int</span> d = top[<span class="number">0</span>]-&gt;count() / n;</div><div class="line">  Dtype epsilon = <span class="number">0.0000001</span>;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</div><div class="line">    Dtype a = caffe_cpu_dot(d, top_data+i*d, top_diff+i*d);</div><div class="line">    caffe_cpu_scale(d, a, top_data+i*d, bottom_diff+i*d);</div><div class="line">    caffe_sub(d, top_diff+i*d, bottom_diff+i*d, bottom_diff+i*d);</div><div class="line">    a = caffe_cpu_dot(d, bottom_data+i*d, bottom_data+i*d);</div><div class="line">    caffe_cpu_scale(d, Dtype(<span class="built_in">pow</span>(a + epsilon, <span class="number">-0.5</span>)),</div><div class="line">            bottom_diff+i*d, bottom_diff+i*d);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CPU_ONLY</span></div><div class="line">STUB_GPU(L2NormalizeLayer);</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line"></div><div class="line">INSTANTIATE_CLASS(L2NormalizeLayer);</div><div class="line">REGISTER_LAYER_CLASS(L2Normalize);</div><div class="line"></div><div class="line">&#125;  <span class="comment">// namespace caffe</span></div></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/19/【论文笔记】Multi-group-Shifting-Attention-Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/19/【论文笔记】Multi-group-Shifting-Attention-Network/" itemprop="url">【论文笔记】Multi-group Shifting Attention Network</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-19T21:47:52+08:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/水滴石穿/" itemprop="url" rel="index">
                    <span itemprop="name">水滴石穿</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>来自百度的ActivityNet Challenge 2017冠军论文 <code>Revisiting the Effectiveness of Off-the-shelf Temporal Modeling Approaches for Large-scale Video Classification</code>。由于只有短短的4页，内容很不详细，自己分析了一部分。</p>
<p>主要提出了一个<code>Multi-group Shifting Attention Network</code>模型用于视频检测，在Kinetics数据集上效果很好。</p>
<p><img src="http://wx2.sinaimg.cn/large/005CRBrHly1g2kjidz7nvj311u0cen0c.jpg" alt="60056469"></p>
<p>Multi-group Shifting Attention Network 的结构如下，其中最重要的便是shifting attention部分</p>
<p><img src="http://wx2.sinaimg.cn/large/005CRBrHly1g2kjj4gdicj314w0i4aej.jpg" alt="80339585"></p>
<p>下面是我的个人理解。</p>
<p>整个结构输入有三部分，RGB，Flow和Audio，分别经过shifting attention最后<br>三份输出concate作为整个视频的representation，进行常规的FC，softmax分类。</p>
<p>下面的SATT就是shifting attention结构的公式。输入X和输出都是矩阵。</p>
<p><img src="http://wx2.sinaimg.cn/large/005CRBrHly1g2kjjgc2mij30s40dqjt0.jpg" alt="70282483"></p>
<p>首先理解X 。比如，我们可以在整个视频中选取10个时间节点，extract对应的RGB，FLow和Audio特征，以RGB为例我们可以得到10张<code>C0 * H0 * W0</code>的图像，经过一个神经网络得到<code>10 * C * H * W</code>的future, 然后将后面3维concate成一个vector，最终得到<code>10 * (C*H*W)</code>的二维矩阵。上面结构图的深蓝色矩形合起来就是这个<code>10 * (C*H*W)</code>矩阵，也是公式中的<code>X</code>，每一个矩形单独是一个<code>C*H*W</code>的vector，来自原始输入的一帧。(以上皆为个人推断，原文未说明X)</p>
<p>文中有一句原话是</p>
<blockquote>
<p>An attention function can be considered as mapping a set of input features to a single output, where the input and output are both matrices that concatenate feature vectors</p>
</blockquote>
<p>文中说X和attention函数的输出都是vector拼接起来的矩阵。而我们推理的X是不同帧RGB经过网络的得到feature拼接起来的。一个帧提供一个<code>C*H*W</code>长的vector，N个帧拼接正好得到了一个<code>N * (C*H*W)</code>的X矩阵。</p>
<p>那么输出也是一个拼接的矩阵怎么解释？还是回到原文</p>
<blockquote>
<p>First, we extract multiple feature sets from the video. For each feature set Xi, we apply Ni different shifting attentions, which we call one attention group, and then we con- catenate the outputs.</p>
</blockquote>
<p>RGB，Flow和Audio分别对应X1,X2,X3,其各自含有Ni帧。比如RGB有10帧(N1=10)，那么就将这10帧对应的X输入到10个不同的SATT(x)，每个SATT(x)的输出是<code>1*(C*H*W)</code>的vector(后面会证明),那么10个不同的输出concate起来呢？没错，是<code>10*(C*H*W)</code>的矩阵，这也印证了原文说的输入输出都是矩阵。需要注意，一个SATT不是attention函数，Ni个合起来才是一个完整的attention函数。</p>
<p>接下来我们分析SATT函数。假设RGB有N帧 ，为表示方便我们把<code>(C*H*W)</code>记作d。</p>
<p>输入X是 <code>N * d</code> ，w是一个vector，而且要和X的转置做内积，所以肯定是 <code>1 * d</code> 。内积的结果是一个<code>1 * N</code>的vector，超参数α是个值不影响维度，再进过softmax，得到的λ也是一个<code>1 * N</code>的vector，对应不同帧的weight。<strong>注意，在这以及能看出来，百度这个shifting attention的本质就是给视频不同位置(帧)的RGB(光流，声音)加权重，找关键帧，而不再考虑时序信息。</strong> 然后因为λX是内积，得到<code>1 * d</code>的vector，所以最终SATT的输出就是一个<code>1 * d</code>的vector。按照之前分析的，RGB的X一共输入到N个不同的SATT，N个输出拼接起来就又是<code>N * d</code>的矩阵了。然后将这个矩阵concate成 <code>1*（N*d）</code>的vector，进行L2 normalize。RGB，Flow和Audio各自normalize完的输出再concate成一个vector，作为整个vedio的representation ，接下来输入到FC，softmax进行分类。</p>
<p>以上也是<code>Multi-group Shifting Attention Network</code>运行的全部流程。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/10/PyCaffe-编译/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/10/PyCaffe-编译/" itemprop="url">PyCaffe 编译</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-10T23:10:02+08:00">
                2017-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Caffe/" itemprop="url" rel="index">
                    <span itemprop="name">Caffe</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>进入caffe根目录 ，执行</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">make pycaffe</div></pre></td></tr></table></figure>
<p><img src="http://wx4.sinaimg.cn/large/005CRBrHly1g2kjlej3i8j30wm0dwq5n.jpg" alt="86047808"></p>
<ul>
<li>导入环境变量</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi ~/.bashrc</div></pre></td></tr></table></figure>
<p>加入下面这一行，注意 = 前后一定不能用有空格</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export PYTHONPATH=/data2/zzy5/jar/pycaffe_tsn/python:$PYTHONPATH</div></pre></td></tr></table></figure>
<p>source环境变量文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">source ~/.bashrc</div></pre></td></tr></table></figure>
<ul>
<li>查看是否配置成功</li>
</ul>
<p>没什么问题<br><img src="http://ws4.sinaimg.cn/large/005CRBrHly1g2kjll5zrfj30w005gmxx.jpg" alt="5273757"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/10/Caffe-io-oversample-的使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/10/Caffe-io-oversample-的使用/" itemprop="url">Caffe io oversample 的使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-10T23:05:25+08:00">
                2017-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Caffe/" itemprop="url" rel="index">
                    <span itemprop="name">Caffe</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>学习一下怎么用，先看源码</p>
<h4 id="caffe-io-oversample"><a href="#caffe-io-oversample" class="headerlink" title="caffe.io.oversample"></a>caffe.io.oversample</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">oversample</span><span class="params">(images, crop_dims)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Crop images into the four corners, center, and their mirrored versions.</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    image : iterable of (H x W x K) ndarrays ，K是通道数，注意是还没有transpose的image</span></div><div class="line"><span class="string">            可以理解成为 (N x H x W x K)</span></div><div class="line"><span class="string">    crop_dims : (height, width) tuple for the crops.</span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    crops : (10*N x H x W x K) ndarray of crops for number of inputs N.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment"># Dimensions and center.</span></div><div class="line">    im_shape = np.array(images[<span class="number">0</span>].shape) <span class="comment"># images[0].shape就是 (H x W x K)</span></div><div class="line">    crop_dims = np.array(crop_dims)      <span class="comment"># (height, width)</span></div><div class="line">    im_center = im_shape[:<span class="number">2</span>] / <span class="number">2.0</span>       <span class="comment"># (H/2 x W/2) ,图片的中心  </span></div><div class="line"></div><div class="line">    <span class="comment"># Make crop coordinates</span></div><div class="line">    h_indices = (<span class="number">0</span>, im_shape[<span class="number">0</span>] - crop_dims[<span class="number">0</span>])</div><div class="line">    w_indices = (<span class="number">0</span>, im_shape[<span class="number">1</span>] - crop_dims[<span class="number">1</span>])</div><div class="line">    crops_ix = np.empty((<span class="number">5</span>, <span class="number">4</span>), dtype=int) <span class="comment"># 存4个角和中心crop的4个分界线坐标</span></div><div class="line">    curr = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> h_indices:</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> w_indices:</div><div class="line">            crops_ix[curr] = (i, j, i + crop_dims[<span class="number">0</span>], j + crop_dims[<span class="number">1</span>])</div><div class="line">            curr += <span class="number">1</span></div><div class="line">    crops_ix[<span class="number">4</span>] = np.tile(im_center, (<span class="number">1</span>, <span class="number">2</span>)) + np.concatenate([</div><div class="line">        -crop_dims / <span class="number">2.0</span>,</div><div class="line">         crop_dims / <span class="number">2.0</span></div><div class="line">    ])</div><div class="line">    crops_ix = np.tile(crops_ix, (<span class="number">2</span>, <span class="number">1</span>))</div><div class="line"></div><div class="line">    <span class="comment"># Extract crops</span></div><div class="line">    <span class="comment"># 返回的crops （ [10*N] x H x W x K） ,4 维的np.array</span></div><div class="line">    crops = np.empty((<span class="number">10</span> * len(images), crop_dims[<span class="number">0</span>], crop_dims[<span class="number">1</span>],</div><div class="line">                      im_shape[<span class="number">-1</span>]), dtype=np.float32)</div><div class="line">    ix = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> im <span class="keyword">in</span> images:</div><div class="line">        <span class="keyword">for</span> crop <span class="keyword">in</span> crops_ix:</div><div class="line">            crops[ix] = im[crop[<span class="number">0</span>]:crop[<span class="number">2</span>], crop[<span class="number">1</span>]:crop[<span class="number">3</span>], :]</div><div class="line">            ix += <span class="number">1</span></div><div class="line">        crops[ix<span class="number">-5</span>:ix] = crops[ix<span class="number">-5</span>:ix, :, ::<span class="number">-1</span>, :]  <span class="comment"># flip for mirrors</span></div><div class="line">    <span class="keyword">return</span> crops</div></pre></td></tr></table></figure>
<h4 id="尝试"><a href="#尝试" class="headerlink" title="尝试"></a>尝试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> caffe</div></pre></td></tr></table></figure>
<p>首先确定一下输入images的维度</p>
<ul>
<li>输入3维，报错</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>img = caffe.io.load_image(<span class="string">'/data2/zzy5/me/some/cat.jpeg'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>img.shape</div><div class="line">(<span class="number">200</span>, <span class="number">200</span>, <span class="number">3</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>cat_over = caffe.io.oversample(img,(<span class="number">100</span>,<span class="number">100</span>))</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">  File <span class="string">"/data2/zzy5/jar/pycaffe_tsn/python/caffe/io.py"</span>, line <span class="number">376</span>, <span class="keyword">in</span> oversample</div><div class="line">    crops[ix] = im[crop[<span class="number">0</span>]:crop[<span class="number">2</span>], crop[<span class="number">1</span>]:crop[<span class="number">3</span>], :]</div><div class="line">IndexError: too many indices <span class="keyword">for</span> array</div></pre></td></tr></table></figure>
<ul>
<li>输入4维，成功执行</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>cat = caffe.io.load_image(<span class="string">'/data2/zzy5/me/some/cat.jpeg'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>dog = caffe.io.load_image(<span class="string">'dog.jpeg'</span>)</div><div class="line"><span class="comment"># 在存放图片的目录启动的python，所以直接用相对路径即可</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>imgs = np.array([cat,dog])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>imgs.shape</div><div class="line">(<span class="number">2</span>, <span class="number">200</span>, <span class="number">200</span>, <span class="number">3</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>imgs_10 = caffe.io.oversample(imgs,(<span class="number">100</span>,<span class="number">100</span>))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>imgs_10.shape</div><div class="line">(<span class="number">20</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>)</div></pre></td></tr></table></figure>
<p>可以看到，输入的(2,200,200,3)，裁剪大小为(100，100),最后得到了(20,100,100,3)</p>
<h4 id="整理"><a href="#整理" class="headerlink" title="整理"></a>整理</h4><p>读图片，oversample，然后结果写图片的完整代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc </div><div class="line"></div><div class="line">cat = caffe.io.load_image(<span class="string">'cat.jpeg'</span>)</div><div class="line">dog = caffe.io.load_image(<span class="string">'dog.jpeg'</span>)</div><div class="line">imgs = np.array([cat,dog])</div><div class="line">imgs_10 = caffe.io.oversample(imgs,(<span class="number">100</span>,<span class="number">100</span>))</div><div class="line">name = [<span class="string">'cat'</span>,<span class="string">'dog'</span>]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">2</span>):</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">10</span>):</div><div class="line">        fullname = name[i] + <span class="string">'_&#123;&#125;.jpeg'</span>.format(j+<span class="number">1</span>)</div><div class="line">        misc.imsave(fullname,imgs_10[<span class="number">10</span>*i+j])</div></pre></td></tr></table></figure>
<p>其中，scipy库中的 misc 可以将np.array存储为jpeg，png等格式的图片，基本用法是</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</div><div class="line">misc.imsave(<span class="string">'lena_new_sz.png'</span>, lena_array)</div></pre></td></tr></table></figure>
<p>最后是生成的sample 效果</p>
<p><img src="http://wx2.sinaimg.cn/large/005CRBrHly1g2kjmrn4bjj30xa0qq4dp.jpg" alt="43831055"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/10/Caffe-io-Transformer类的一点理解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/10/Caffe-io-Transformer类的一点理解/" itemprop="url">Caffe io Transformer类的一点理解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-10T23:04:55+08:00">
                2017-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Caffe/" itemprop="url" rel="index">
                    <span itemprop="name">Caffe</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>有两种最常见的初始化Transformer的方法，第二种根据net输入层shape才能真正体现tansformer的意义<br>第一种可以理解为我们自己知道net输入层shape后，手动把这个值填上去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>:(<span class="number">1</span>,<span class="number">3</span>,<span class="number">256</span>,<span class="number">340</span>)&#125;) </div><div class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</div></pre></td></tr></table></figure>
<p>设定的是一个 4维向量，而处理是输入的图像是单个3维的<br>注意是必须单个，不能一次性输入batch size个进行transform</p>
<p>而问题来了，实际上整个transformer 的 preprocess 过程只用到了4维里面的后3维（合法性检测，resize等），那为什么初始化<br>transformer的时候输入的是一个4维呢？</p>
<p>这时候，我们就该回去想，这个Transformer是干什么的？</p>
<p>没错，Pre-processing，将输入图片预处理成<br>deploy net 输入层可以接受的shape。所以第一步就是要知道输入层需要什么样的shape，因此初始化的时候<br>caffe.io.Transformer({‘data’:(1,3,256,340)})，这个(1,3,256,340)就必须是对应与deploy net<br>输入层的shape.而在deploy net的prototxt中shape往往都是写成4个dims的形式，从而是4维的。</p>
<p>所以，虽然transformer只要用到这4维中的后3维，但它没必要单独取3维读，还不如全读，用的时候用3维就好了。</p>
<h4 id="Caffe-io-Transformer"><a href="#Caffe-io-Transformer" class="headerlink" title="Caffe.io.Transformer"></a>Caffe.io.Transformer</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## Pre-processing</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>:</span></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="string">Transform input for feeding into a Net.</span></div><div class="line"><span class="string">Note: this is mostly for illustrative purposes and it is likely better</span></div><div class="line"><span class="string">to define your own input preprocessing routine for your needs.</span></div><div class="line"><span class="string">Parameters</span></div><div class="line"><span class="string">----------</span></div><div class="line"><span class="string">net : a Net for which the input should be prepared</span></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inputs)</span>:</span></div><div class="line">    self.inputs = inputs <span class="comment">#  inputs存的是一个name和shape的字典，比如 &#123;'data':(1,3,256,340)&#125;</span></div><div class="line">    self.transpose = &#123;&#125;  <span class="comment"># Transformer中的这些参数全部是字典dict</span></div><div class="line">    self.channel_swap = &#123;&#125;</div><div class="line">    self.raw_scale = &#123;&#125;</div><div class="line">    self.mean = &#123;&#125;</div><div class="line">    self.input_scale = &#123;&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__check_input</span><span class="params">(self, in_)</span>:</span></div><div class="line">    <span class="keyword">if</span> in_ <span class="keyword">not</span> <span class="keyword">in</span> self.inputs:</div><div class="line">        <span class="keyword">raise</span> Exception(<span class="string">'&#123;&#125; is not one of the net inputs: &#123;&#125;'</span>.format(</div><div class="line">            in_, self.inputs))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, in_, data)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Format input for Caffe:</span></div><div class="line"><span class="string">    - convert to single</span></div><div class="line"><span class="string">    - resize to input dimensions (preserving number of channels)</span></div><div class="line"><span class="string">    - transpose dimensions to K x H x W</span></div><div class="line"><span class="string">    - reorder channels (for instance color to BGR)</span></div><div class="line"><span class="string">    - scale raw input (e.g. from [0, 1] to [0, 255] for ImageNet models)</span></div><div class="line"><span class="string">    - subtract mean</span></div><div class="line"><span class="string">    - scale feature</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    in_ : name of input blob to preprocess for</span></div><div class="line"><span class="string">    data : (H' x W' x K) ndarray  ！！！！输入data必须是单个image，后面有限制</span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    caffe_in : (K x H x W) ndarray for input to a Net</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    caffe_in = data.astype(np.float32, copy=<span class="keyword">False</span>)</div><div class="line">    transpose = self.transpose.get(in_)</div><div class="line">    channel_swap = self.channel_swap.get(in_)</div><div class="line">    raw_scale = self.raw_scale.get(in_)</div><div class="line">    mean = self.mean.get(in_)</div><div class="line">    input_scale = self.input_scale.get(in_)</div><div class="line">    in_dims = self.inputs[in_][<span class="number">2</span>:] <span class="comment"># in_dims即inputs设定的shape的(H,W)</span></div><div class="line">    <span class="comment"># 检查输入data的(H,W)是否与in_dims一样,注意这里[:2]限制了输入data只能是单个iamge</span></div><div class="line">    <span class="keyword">if</span> caffe_in.shape[:<span class="number">2</span>] != in_dims: </div><div class="line">        caffe_in = resize_image(caffe_in, in_dims)</div><div class="line">    <span class="keyword">if</span> transpose <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        caffe_in = caffe_in.transpose(transpose)</div><div class="line">    <span class="keyword">if</span> channel_swap <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:  <span class="comment"># 如果没有transpose第一维不是通道，这里会报错吧。。。</span></div><div class="line">        caffe_in = caffe_in[channel_swap, :, :]</div><div class="line">    <span class="keyword">if</span> raw_scale <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        caffe_in *= raw_scale</div><div class="line">    <span class="keyword">if</span> mean <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        caffe_in -= mean</div><div class="line">    <span class="keyword">if</span> input_scale <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        caffe_in *= input_scale</div><div class="line">    <span class="keyword">return</span> caffe_in</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess</span><span class="params">(self, in_, data)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Invert Caffe formatting; see preprocess().</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    decaf_in = data.copy().squeeze()</div><div class="line">    transpose = self.transpose.get(in_)</div><div class="line">    channel_swap = self.channel_swap.get(in_)</div><div class="line">    raw_scale = self.raw_scale.get(in_)</div><div class="line">    mean = self.mean.get(in_)</div><div class="line">    input_scale = self.input_scale.get(in_)</div><div class="line">    <span class="keyword">if</span> input_scale <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        decaf_in /= input_scale</div><div class="line">    <span class="keyword">if</span> mean <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        decaf_in += mean</div><div class="line">    <span class="keyword">if</span> raw_scale <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        decaf_in /= raw_scale</div><div class="line">    <span class="keyword">if</span> channel_swap <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        decaf_in = decaf_in[np.argsort(channel_swap), :, :]</div><div class="line">    <span class="keyword">if</span> transpose <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        decaf_in = decaf_in.transpose(np.argsort(transpose))</div><div class="line">    <span class="keyword">return</span> decaf_in</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_transpose</span><span class="params">(self, in_, order)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Set the input channel order for e.g. RGB to BGR conversion</span></div><div class="line"><span class="string">    as needed for the reference ImageNet model.</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    in_ : which input to assign this channel order</span></div><div class="line"><span class="string">    order : the order to transpose the dimensions</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    <span class="keyword">if</span> len(order) != len(self.inputs[in_]) - <span class="number">1</span>:  <span class="comment">#注意，这里只比较设定shape的后3维</span></div><div class="line">        <span class="keyword">raise</span> Exception(<span class="string">'Transpose order needs to have the same number of '</span></div><div class="line">                        <span class="string">'dimensions as the input.'</span>)</div><div class="line">    self.transpose[in_] = order</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_channel_swap</span><span class="params">(self, in_, order)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Set the input channel order for e.g. RGB to BGR conversion</span></div><div class="line"><span class="string">    as needed for the reference ImageNet model.</span></div><div class="line"><span class="string">    N.B. this assumes the channels are the first dimension AFTER transpose.</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    in_ : which input to assign this channel order</span></div><div class="line"><span class="string">    order : the order to take the channels.</span></div><div class="line"><span class="string">        (2,1,0) maps RGB to BGR for example.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    <span class="keyword">if</span> len(order) != self.inputs[in_][<span class="number">1</span>]:</div><div class="line">        <span class="keyword">raise</span> Exception(<span class="string">'Channel swap needs to have the same number of '</span></div><div class="line">                        <span class="string">'dimensions as the input channels.'</span>)</div><div class="line">    self.channel_swap[in_] = order</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_raw_scale</span><span class="params">(self, in_, scale)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Set the scale of raw features s.t. the input blob = input * scale.</span></div><div class="line"><span class="string">    While Python represents images in [0, 1], certain Caffe models</span></div><div class="line"><span class="string">    like CaffeNet and AlexNet represent images in [0, 255] so the raw_scale</span></div><div class="line"><span class="string">    of these models must be 255.</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    in_ : which input to assign this scale factor</span></div><div class="line"><span class="string">    scale : scale coefficient</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    self.raw_scale[in_] = scale</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_mean</span><span class="params">(self, in_, mean)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Set the mean to subtract for centering the data.</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    in_ : which input to assign this mean.</span></div><div class="line"><span class="string">    mean : mean ndarray (input dimensional or broadcastable)</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    ms = mean.shape</div><div class="line">    <span class="keyword">if</span> mean.ndim == <span class="number">1</span>:</div><div class="line">        <span class="comment"># broadcast channels</span></div><div class="line">        <span class="keyword">if</span> ms[<span class="number">0</span>] != self.inputs[in_][<span class="number">1</span>]:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Mean channels incompatible with input.'</span>)</div><div class="line">        mean = mean[:, np.newaxis, np.newaxis]</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># elementwise mean</span></div><div class="line">        <span class="keyword">if</span> len(ms) == <span class="number">2</span>:</div><div class="line">            ms = (<span class="number">1</span>,) + ms</div><div class="line">        <span class="keyword">if</span> len(ms) != <span class="number">3</span>:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Mean shape invalid'</span>)</div><div class="line">        <span class="keyword">if</span> ms != self.inputs[in_][<span class="number">1</span>:]:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Mean shape incompatible with input shape.'</span>)</div><div class="line">    self.mean[in_] = mean</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_input_scale</span><span class="params">(self, in_, scale)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Set the scale of preprocessed inputs s.t. the blob = blob * scale.</span></div><div class="line"><span class="string">    N.B. input_scale is done AFTER mean subtraction and other preprocessing</span></div><div class="line"><span class="string">    while raw_scale is done BEFORE.</span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    in_ : which input to assign this scale factor</span></div><div class="line"><span class="string">    scale : scale coefficient</span></div><div class="line"><span class="string">    """</span></div><div class="line">    self.__check_input(in_)</div><div class="line">    self.input_scale[in_] = scale</div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/09/PyCaffe-的一些-Demo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/09/PyCaffe-的一些-Demo/" itemprop="url">PyCaffe 的一些 Demo</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-09T22:32:27+08:00">
                2017-10-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Caffe/" itemprop="url" rel="index">
                    <span itemprop="name">Caffe</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="E-1"><a href="#E-1" class="headerlink" title="E 1"></a>E 1</h3><p>用训练好的模型，来对测试集进行测试，并输出每个样本的分类结果的实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding=utf-8 </span></div><div class="line">       </div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> caffe </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </div><div class="line">root=<span class="string">'/home/liuyun/caffe/'</span>   <span class="comment">#根目录 </span></div><div class="line">deploy=root + <span class="string">'examples/DR_grade/deploy.prototxt'</span>    <span class="comment">#deploy文件 </span></div><div class="line">caffe_model=root + <span class="string">'models/DR/model1/DRnet_iter_40000.caffemodel'</span>  <span class="comment">#训练好的 caffemodel </span></div><div class="line"> </div><div class="line"> </div><div class="line"><span class="keyword">import</span> os</div><div class="line">dir = root+<span class="string">'examples/DR_grade/test_512/'</span></div><div class="line">filelist=[]</div><div class="line">filenames = os.listdir(dir)</div><div class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> filenames:</div><div class="line">   fullfilename = os.path.join(dir,fn)</div><div class="line">   filelist.append(fullfilename)</div><div class="line"> </div><div class="line"> </div><div class="line"><span class="comment"># img=root+'data/DRIVE/test/60337.jpg'   #随机找的一张待测图片 </span></div><div class="line"> </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">Test</span><span class="params">(img)</span>:</span></div><div class="line">      </div><div class="line">    net = caffe.Net(deploy,caffe_model,caffe.TEST)   <span class="comment">#加载model和network </span></div><div class="line">       </div><div class="line">    <span class="comment">#图片预处理设置 </span></div><div class="line">    transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)  <span class="comment">#设定图片的shape格式(1,3,28,28) </span></div><div class="line">    transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))    <span class="comment">#改变维度的顺序，由原始图片(28,28,3)变为(3,28,28) </span></div><div class="line">    <span class="comment">#transformer.set_mean('data', np.load(mean_file).mean(1).mean(1))    #减去均值，前面训练模型时没有减均值，这儿就不用 </span></div><div class="line">    transformer.set_raw_scale(<span class="string">'data'</span>, <span class="number">255</span>)    <span class="comment"># 缩放到【0，255】之间 </span></div><div class="line">    transformer.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))   <span class="comment">#交换通道，将图片由RGB变为BGR </span></div><div class="line">       </div><div class="line">    im=caffe.io.load_image(img)                   <span class="comment">#加载图片 </span></div><div class="line">    net.blobs[<span class="string">'data'</span>].data[...] = transformer.preprocess(<span class="string">'data'</span>,im)      <span class="comment">#执行上面设置的图片预处理操作，并将图片载入到blob中 </span></div><div class="line">       </div><div class="line">    <span class="comment">#执行测试 </span></div><div class="line">    out = net.forward() </div><div class="line">       </div><div class="line">    labels = np.loadtxt(labels_filename, str, delimiter=<span class="string">'\t'</span>)   <span class="comment">#读取类别名称文件 </span></div><div class="line">    prob= net.blobs[<span class="string">'prob'</span>].data[<span class="number">0</span>].flatten() <span class="comment">#取出最后一层（prob）属于某个类别的概率值，并打印,'prob'为最后一层的名称</span></div><div class="line">    <span class="keyword">print</span> prob </div><div class="line">    order=prob.argsort()[<span class="number">4</span>]  <span class="comment">#将概率值排序，取出最大值所在的序号 ,9指的是分为0-9十类 </span></div><div class="line">    <span class="comment">#argsort()函数是从小到大排列 </span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the class is:'</span>,labels[order]   <span class="comment">#将该序号转换成对应的类别名称，并打印 </span></div><div class="line">    f=file(<span class="string">"/home/liuyun/caffe/examples/DR_grade/label.txt"</span>,<span class="string">"a+"</span>)</div><div class="line">    f.writelines(img+<span class="string">' '</span>+labels[order]+<span class="string">'\n'</span>)</div><div class="line"> </div><div class="line">labels_filename = root +<span class="string">'examples/DR_grade/DR.txt'</span>    <span class="comment">#类别名称文件，将数字标签转换回类别名称 </span></div><div class="line"> </div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(filelist)):</div><div class="line">    img= filelist[i]</div><div class="line">    Test(img)</div></pre></td></tr></table></figure>
<h3 id="E-2"><a href="#E-2" class="headerlink" title="E 2"></a>E 2</h3><p>分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> caffe</div><div class="line"></div><div class="line"><span class="comment"># caffemodel文件</span></div><div class="line">MODEL_FILE = <span class="string">'model/_iter_10000.caffemodel'</span></div><div class="line"><span class="comment"># deploy文件，参考/caffe/models/bvlc_alexnet/deploy.prototxt</span></div><div class="line">DEPLOY_FILE = <span class="string">'deploy.prototxt'</span></div><div class="line"><span class="comment"># 测试图片存放文件夹</span></div><div class="line">TEST_ROOT = <span class="string">'datas/'</span></div><div class="line"></div><div class="line">caffe.set_mode_gpu()</div><div class="line">net = caffe.Net(DEPLOY_FILE, MODEL_FILE, caffe.TEST)</div><div class="line"></div><div class="line"><span class="comment"># 'data'对应于deploy文件：</span></div><div class="line"><span class="comment"># input: "data"</span></div><div class="line"><span class="comment"># input_dim: 1</span></div><div class="line"><span class="comment"># input_dim: 3</span></div><div class="line"><span class="comment"># input_dim: 32</span></div><div class="line"><span class="comment"># input_dim: 96</span></div><div class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</div><div class="line"><span class="comment"># python读取的图片文件格式为H×W×K，需转化为K×H×W</span></div><div class="line">transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</div><div class="line"><span class="comment"># python中将图片存储为[0, 1]，而caffe中将图片存储为[0, 255]，</span></div><div class="line"><span class="comment"># 所以需要一个转换</span></div><div class="line">transformer.set_raw_scale(<span class="string">'data'</span>, <span class="number">255</span>)</div><div class="line"><span class="comment"># caffe中图片是BGR格式，而原始格式是RGB，所以要转化</span></div><div class="line">transformer.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>))</div><div class="line"><span class="comment"># 将输入图片格式转化为合适格式（与deploy文件相同）</span></div><div class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">96</span>)</div><div class="line"></div><div class="line"><span class="comment"># 详见/caffe/python/caffe/io.py</span></div><div class="line">img = caffe.io.load_image(<span class="string">'temp.jpg'</span>)</div><div class="line"><span class="comment"># 读取的图片文件格式为H×W×K，需转化</span></div><div class="line"></div><div class="line"><span class="comment"># 数据输入、预处理</span></div><div class="line">net.blobs[<span class="string">'data'</span>].data[...] = transformer.preprocess(<span class="string">'data'</span>, img)</div><div class="line"><span class="comment"># 前向迭代，即分类</span></div><div class="line">out = net.forward()</div><div class="line"><span class="comment"># 输出结果为各个可能分类的概率分布</span></div><div class="line">pridects = out[<span class="string">'prob'</span>]</div><div class="line"><span class="comment"># 上述'prob'来源于deploy文件：</span></div><div class="line"><span class="comment"># layer &#123;</span></div><div class="line"><span class="comment">#   name: "prob"</span></div><div class="line"><span class="comment">#   type: "Softmax"</span></div><div class="line"><span class="comment">#   bottom: "ip2"</span></div><div class="line"><span class="comment">#   top: "prob"</span></div><div class="line"><span class="comment"># &#125;</span></div><div class="line"></div><div class="line">pridect = pridects.argmax()</div></pre></td></tr></table></figure>
<h3 id="E-3"><a href="#E-3" class="headerlink" title="E 3"></a>E 3</h3><p>手动裁剪图片</p>
<p>在caffe中，如果定义了crop_size，那么在train时会对大于crop_size的图片进行随机裁剪，而在test时只是截取中间部分（详见/caffe/src/caffe/data_transformer.cpp）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> // We only do random crop when we do training.</div><div class="line">  if (phase_ == TRAIN) &#123;</div><div class="line">    h_off = Rand(datum_height - crop_size + 1);</div><div class="line">    w_off = Rand(datum_width - crop_size + 1);</div><div class="line">  &#125; else &#123;</div><div class="line">    h_off = (datum_height - crop_size) / 2;</div><div class="line">    w_off = (datum_width - crop_size) / 2;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在pycaffe利用caffemodel进行分类时，我们使用的是caffe.TEST模式，如果我们输入的图片尺寸大于crop_size，那么图片会被裁剪，但是测试的只是图片中间部分的信息。</p>
<p>我们可以手动将图片裁剪并导入pycaffe中，这样能够提高识别率（pycaffe利用caffemodel进行分类中：进行分类这一步改为如下）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 记录分类概率分布</span></div><div class="line">pridects = np.zeros((<span class="number">1</span>, CLASS_NUM))</div><div class="line"></div><div class="line"><span class="comment"># 图片维度（高、宽）</span></div><div class="line">img_shape = np.array(img.shape)</div><div class="line"><span class="comment"># 裁剪的大小（高、宽）</span></div><div class="line">crop_dims = (<span class="number">32</span>, <span class="number">96</span>)</div><div class="line">crop_dims = np.array(crop_dims)</div><div class="line"><span class="comment"># 这里使用的图片高度全部固定为32，长度可变，最小为96</span></div><div class="line"><span class="comment"># 裁剪起点为0，终点为w_range</span></div><div class="line">w_range = img_shape[<span class="number">1</span>] - crop_dims[<span class="number">1</span>]</div><div class="line"><span class="comment"># 从左往右剪一遍，再从右往左剪一遍，步长为96/4=24</span></div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>, w_range + <span class="number">1</span>, crop_dims[<span class="number">1</span>] / <span class="number">4</span>) + range(w_range, <span class="number">1</span>, -crop_dims[<span class="number">1</span>] / <span class="number">4</span>):</div><div class="line">    <span class="comment"># 裁剪图片</span></div><div class="line">    crop_img = img[:, k:k + crop_dims[<span class="number">1</span>], :]</div><div class="line">    <span class="comment"># 数据输入、预处理</span></div><div class="line">    net.blobs[<span class="string">'data'</span>].data[...] = transformer.preprocess(<span class="string">'data'</span>, crop_img)</div><div class="line">    <span class="comment"># 前向迭代，即分类</span></div><div class="line">    out = net.forward()</div><div class="line">    <span class="comment"># 每一次分类，概率分布叠加</span></div><div class="line">    pridects += out[<span class="string">'prob'</span>]</div><div class="line"></div><div class="line"><span class="comment"># 取最大的概率分布为最终结果</span></div><div class="line">pridect = pridects.argmax()</div></pre></td></tr></table></figure>
<p>caffe中提供了过采样的方法（oversample），详见/caffe/python/caffe/io.py，裁剪的是图片中央、4个角以及镜像共10张图片。</p>
<h3 id="E-4"><a href="#E-4" class="headerlink" title="E 4"></a>E 4</h3><p>利用pycaffe包装好的classifier.py来进行分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> caffe</div><div class="line"></div><div class="line"><span class="comment"># caffemodel文件</span></div><div class="line">MODEL_FILE = <span class="string">'model/_iter_10000.caffemodel'</span></div><div class="line"><span class="comment"># deploy文件，参考/caffe/models/bvlc_alexnet/deploy.prototxt</span></div><div class="line">DEPLOY_FILE = <span class="string">'deploy.prototxt'</span></div><div class="line"><span class="comment"># 测试图片存放文件夹</span></div><div class="line">TEST_ROOT = <span class="string">'datas/'</span></div><div class="line"></div><div class="line">caffe.set_mode_gpu()</div><div class="line"></div><div class="line">net = caffe.Classifier(MODEL_FILE, PRETRAIN_FILE,</div><div class="line">                       raw_scale=<span class="number">255</span>, channel_swap=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>))</div><div class="line"></div><div class="line"><span class="comment"># 详见/caffe/python/caffe/io.py</span></div><div class="line">img = caffe.io.load_image(<span class="string">'temp.jpg'</span>)</div><div class="line"><span class="comment"># 读取的图片文件格式为H×W×K，需转化</span></div><div class="line"></div><div class="line"><span class="comment"># 需注意第一个参数为数组</span></div><div class="line"><span class="comment"># 默认采用过采样（详见**/caffe/python/caffe/io.py**），这里取消</span></div><div class="line">out = net.predict([img], oversample=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># 输出结果为各个可能分类的概率分布</span></div><div class="line"></div><div class="line">pridect = out.argmax()</div></pre></td></tr></table></figure>
<h3 id="E-5"><a href="#E-5" class="headerlink" title="E 5"></a>E 5</h3><p>预测及其特征可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding=utf-8</span></div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> shutil</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"><span class="comment">#因为RGB和BGR需要调换一下才能显示</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">showimage</span><span class="params">(im)</span>:</span></div><div class="line">	<span class="keyword">if</span> im.ndim == <span class="number">3</span>:</div><div class="line">		im = im[:, :, ::<span class="number">-1</span>]</div><div class="line">	plt.set_cmap(<span class="string">'jet'</span>)</div><div class="line">	plt.imshow(im)</div><div class="line">	plt.show()</div><div class="line"></div><div class="line"><span class="comment">#特征可视化显示，padval用于调整亮度</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span><span class="params">(data, padsize=<span class="number">1</span>, padval=<span class="number">0</span>)</span>:</span></div><div class="line">	data -= data.min()</div><div class="line">	data /= data.max()</div><div class="line"></div><div class="line">	<span class="comment">#因为我们要把某一层的特征图都显示到一个figure上，因此需要计算每个图片占用figure多少比例，以及绘制的位置</span></div><div class="line">	n = int(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</div><div class="line">	<span class="comment"># padding是每个维度扩充的数量</span></div><div class="line">	padding = ((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]), (<span class="number">0</span>, padsize), (<span class="number">0</span>, padsize)) + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>)</div><div class="line">	data = np.pad(data, padding, mode=<span class="string">'constant'</span>, constant_values=(padval, padval))</div><div class="line">	<span class="comment"># pad with zero (black)这里该为了黑色，可以更容易看出最后一列中拓展的样子</span></div><div class="line"></div><div class="line">	<span class="comment"># tile the filters into an image</span></div><div class="line">	data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + tuple(range(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</div><div class="line">	data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</div><div class="line"></div><div class="line">	showimage(data)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#设置caffe源码所在的路径</span></div><div class="line">caffe_root = <span class="string">'../../../caffe/'</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">'python'</span>)</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#加载均值文件</span></div><div class="line">mean_filename=<span class="string">'./imagenet_mean.binaryproto'</span></div><div class="line">proto_data = open(mean_filename, <span class="string">"rb"</span>).read()</div><div class="line">a = caffe.io.caffe_pb2.BlobProto.FromString(proto_data)</div><div class="line">mean  = caffe.io.blobproto_to_array(a)[<span class="number">0</span>]</div><div class="line"></div><div class="line"><span class="comment">#创建网络，并加载已经训练好的模型文件</span></div><div class="line">gender_net_pretrained=<span class="string">'./caffenet_train_iter_1500.caffemodel'</span></div><div class="line">gender_net_model_file=<span class="string">'./deploy_gender.prototxt'</span></div><div class="line">gender_net = caffe.Classifier(gender_net_model_file, gender_net_pretrained,mean=mean,</div><div class="line">					   channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),<span class="comment">#RGB通道与BGR</span></div><div class="line">					   raw_scale=<span class="number">255</span>,<span class="comment">#把图片归一化到0~1之间</span></div><div class="line">					   image_dims=(<span class="number">256</span>, <span class="number">256</span>))<span class="comment">#设置输入图片的大小</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#预测分类及其可特征视化</span></div><div class="line">gender_list=[<span class="string">'Male'</span>,<span class="string">'Female'</span>]</div><div class="line">input_image = caffe.io.load_image(<span class="string">'1.jpg'</span>)<span class="comment">#读取图片</span></div><div class="line"></div><div class="line">prediction_gender=gender_net.predict([input_image])<span class="comment">#预测图片性别</span></div><div class="line"><span class="comment">#打印我们训练每一层的参数形状</span></div><div class="line"><span class="keyword">print</span> <span class="string">'params:'</span></div><div class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> gender_net.params.items():</div><div class="line">	<span class="keyword">print</span> <span class="string">'weight:'</span></div><div class="line">	<span class="keyword">print</span> (k, v[<span class="number">0</span>].data.shape)<span class="comment">#在每一层的参数blob中，caffe用vector存储了两个blob变量，用v[0]表示weight</span></div><div class="line">	<span class="keyword">print</span> <span class="string">'b:'</span></div><div class="line">	<span class="keyword">print</span> (k, v[<span class="number">1</span>].data.shape)<span class="comment">#用v[1]表示偏置参数</span></div><div class="line"><span class="comment">#conv1滤波器可视化</span></div><div class="line">filters = gender_net.params[<span class="string">'conv1'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</div><div class="line"><span class="comment">#conv2滤波器可视化</span></div><div class="line"><span class="string">'''filters = gender_net.params['conv2'][0].data</span></div><div class="line"><span class="string">vis_square(filters[:48].reshape(48**2, 5, 5))'''</span></div><div class="line"><span class="comment">#特征图</span></div><div class="line"><span class="keyword">print</span> <span class="string">'feature maps:'</span></div><div class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> gender_net.blobs.items():</div><div class="line">	<span class="keyword">print</span> (k, v.data.shape);</div><div class="line">	feat = gender_net.blobs[k].data[<span class="number">0</span>,<span class="number">0</span>:<span class="number">4</span>]<span class="comment">#显示名字为k的网络层,第一张图片所生成的4张feature maps</span></div><div class="line">	vis_square(feat, padval=<span class="number">1</span>)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#显示原图片，以及分类预测结果</span></div><div class="line">str_gender=gender_list[prediction_gender[<span class="number">0</span>].argmax()]</div><div class="line"><span class="keyword">print</span> str_gender</div><div class="line"></div><div class="line">plt.imshow(input_image)</div><div class="line">plt.title(str_gender)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<hr>
<h6 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h6><p><a href="http://blog.csdn.net/u011762313/article/details/48342495" target="_blank" rel="external">Caffe学习：pycaffe利用caffemodel进行分类</a></p>
<p><a href="http://blog.csdn.net/u011762313/article/details/48343799" target="_blank" rel="external">pycaffe利用caffemodel进行分类=&gt;裁剪图片</a></p>
<p><a href="http://blog.csdn.net/hjimce/article/details/48933813" target="_blank" rel="external"> 深度学习（六）caffe入门学习</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/28/Caffe训练prototxt-的一些Demo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="半城秋雨半城月">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="牧羊人小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/28/Caffe训练prototxt-的一些Demo/" itemprop="url">Caffe训练prototxt 的一些Demo</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-09-28T23:00:27+08:00">
                2017-09-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Caffe/" itemprop="url" rel="index">
                    <span itemprop="name">Caffe</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h4><p><img src="http://o7f7k8xtl.bkt.clouddn.com/17-9-28/40239903.jpg?imageView2/0/w/400/h/400" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">name:<span class="string">"logisticregression"</span>  <span class="comment"># 开头先定义网络的名字</span></div><div class="line">layer&#123;</div><div class="line">    name:<span class="string">"mnist"</span></div><div class="line">    type:<span class="string">"Data"</span></div><div class="line">    top:<span class="string">"data"</span></div><div class="line">    top:<span class="string">"label"</span></div><div class="line">    data_param&#123;</div><div class="line">      source:<span class="string">"yoursource"</span></div><div class="line">      batch_size:yoursize</div><div class="line">      &#125;</div><div class="line">&#125;</div><div class="line">layer &#123;</div><div class="line">    name:<span class="string">"ip"</span></div><div class="line">    type:<span class="string">"InnerProduct"</span></div><div class="line">    bottom:<span class="string">"data"</span></div><div class="line">    top:<span class="string">"ip"</span></div><div class="line">    inner_product_param&#123;</div><div class="line">      num_output:<span class="number">2</span></div><div class="line">      &#125;</div><div class="line">&#125;</div><div class="line">layer &#123;</div><div class="line">    name:<span class="string">"loss"</span></div><div class="line">    type:<span class="string">"SoftmaxWithLoss"</span></div><div class="line">    bottom:<span class="string">"ip"</span></div><div class="line">    bottom:<span class="string">"label"</span></div><div class="line">    top:<span class="string">"loss"</span>&#125;</div></pre></td></tr></table></figure>
<h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><p><img src="http://ww1.sinaimg.cn/large/005CRBrHly1fjz2inf19mj30vd0b0wg5.jpg" alt=""><br><img src="http://o7f7k8xtl.bkt.clouddn.com/17-9-28/13007114.jpg?imageView2/0/w/500/h/500" alt=""></p>
<ul>
<li>Data layer</li>
</ul>
<p>首先是定义网络名字 <code>name: &quot;LeNet&quot;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">name: <span class="string">"LeNet"</span></div><div class="line"><span class="comment">#==============定义TRAIN的数据层============================================</span></div><div class="line"></div><div class="line">layer&#123;</div><div class="line">    name:<span class="string">"mnist"</span> <span class="comment">#定义该层的名字</span></div><div class="line">    type:<span class="string">"Data"</span><span class="comment">#该层的类型是数据,这里的type还有MemoryData(内存读取)HDF5Dats，</span></div><div class="line">               <span class="comment">#HDF5output，ImageData等</span></div><div class="line">    top:<span class="string">"data"</span> <span class="comment"># 生成一个data blob</span></div><div class="line">    top:<span class="string">"label"</span> <span class="comment"># 生成一个label blob</span></div><div class="line">    include &#123;</div><div class="line">        phase: TRAIN <span class="comment">#说明该层只在TRAIN阶段使用</span></div><div class="line">    &#125;</div><div class="line">    transform_param&#123;</div><div class="line">        scale:<span class="number">0.00390625</span> <span class="comment"># 数据归一化系数，1/256，归一到[0,1)</span></div><div class="line">        &#125;<span class="comment">#预处理如减均值，尺寸变换，随机剪，镜像等</span></div><div class="line">    data_param&#123;</div><div class="line">      source:<span class="string">"E:/MyCode/DL/caffe-master/examples/mnist/mnist_train_lmdb"</span> <span class="comment">#训练数据的路径</span></div><div class="line">      batch_size:<span class="number">64</span> <span class="comment">#批量处理的大小</span></div><div class="line">      backend:LMDB <span class="comment">#默认为使用leveldb</span></div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">#==============定义TEST的数据层============================================</span></div><div class="line">layer &#123; </div><div class="line">    name: <span class="string">"mnist"</span></div><div class="line">    type: <span class="string">"Data"</span></div><div class="line">    top: <span class="string">"data"</span></div><div class="line">    top: <span class="string">"label"</span></div><div class="line">    include &#123;</div><div class="line">        phase: TEST <span class="comment">#说明该层只在TEST阶段使用</span></div><div class="line">    &#125;</div><div class="line">    transform_param &#123;</div><div class="line">        scale: <span class="number">0.00390625</span></div><div class="line">    &#125;</div><div class="line">    data_param &#123;</div><div class="line">        source: <span class="string">"E:/MyCode/DL/caffe-master/examples/mnist/mnist_test_lmdb"</span> <span class="comment">#测试数据的路径</span></div><div class="line">        batch_size: <span class="number">100</span></div><div class="line">        backend: LMDB</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Conv1 Layer</li>
</ul>
<p>(batch_size，1，28，28) -&gt; (batch_size，20，24，24)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义卷积层1=============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"conv1"</span>       <span class="comment">#该层的名字conv1，即卷积层1</span></div><div class="line">  type: <span class="string">"Convolution"</span> <span class="comment">#该层的类型是卷积层</span></div><div class="line">  bottom: <span class="string">"data"</span>      <span class="comment">#该层使用的数据是由数据层提供的data blob</span></div><div class="line">  top: <span class="string">"conv1"</span>        <span class="comment">#该层生成的数据是conv1</span></div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">1</span>        <span class="comment">#weight learning rate(简写为lr)权值的学习率，1表示该值是lenet_solver.prototxt中base_lr: 0.01的1倍</span></div><div class="line">  &#125;</div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">2</span>        <span class="comment">#bias learning rate偏移值的学习率，2表示该值是lenet_solver.prototxt中base_lr: 0.01的2倍</span></div><div class="line">  &#125;</div><div class="line">  convolution_param &#123;</div><div class="line">    num_output: <span class="number">20</span>    <span class="comment">#产生20个输出通道，即20个过滤器</span></div><div class="line">    kernel_size: <span class="number">5</span>    <span class="comment">#卷积核的大小为5*5</span></div><div class="line">    stride: <span class="number">1</span>         <span class="comment">#卷积核移动的步幅为1</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"xavier"</span>  <span class="comment">#xavier算法，根据输入和输出的神经元的个数自动初始化权值比例</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span>  <span class="comment">#将偏移值初始化为“稳定”状态，即设为默认值0</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Pool1 Layer</li>
</ul>
<p>(batch_size，20，24，24) -&gt; (batch_size，20，12，12)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义池化层1=============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"pool1"</span></div><div class="line">  type: <span class="string">"Pooling"</span></div><div class="line">  bottom: <span class="string">"conv1"</span>     <span class="comment">#该层使用的数据是由conv1层提供的conv1</span></div><div class="line">  top: <span class="string">"pool1"</span>        <span class="comment">#该层生成的数据是pool1</span></div><div class="line">  pooling_param &#123;</div><div class="line">    pool: MAX         <span class="comment">#采用最大值池化</span></div><div class="line">    kernel_size: <span class="number">2</span>    <span class="comment">#池化核大小为2*2</span></div><div class="line">    stride: <span class="number">2</span>         <span class="comment">#池化核移动的步幅为2，即非重叠移动</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Conv2 Layer</li>
</ul>
<p>(batch_size，20，12，12) -&gt; (batch_size，50，8，8)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义卷积层2=============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"conv2"</span></div><div class="line">  type: <span class="string">"Convolution"</span></div><div class="line">  bottom: <span class="string">"pool1"</span></div><div class="line">  top: <span class="string">"conv2"</span></div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">1</span></div><div class="line">  &#125;</div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">  convolution_param &#123;</div><div class="line">    num_output: <span class="number">50</span></div><div class="line">    kernel_size: <span class="number">5</span></div><div class="line">    stride: <span class="number">1</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"xavier"</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Pool2 Layer</li>
</ul>
<p>(batch_size，50，8，8) -&gt; (batch_size，50，4，4)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义池化层2=============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"pool2"</span></div><div class="line">  type: <span class="string">"Pooling"</span></div><div class="line">  bottom: <span class="string">"conv2"</span></div><div class="line">  top: <span class="string">"pool2"</span></div><div class="line">  pooling_param &#123;</div><div class="line">    pool: MAX</div><div class="line">    kernel_size: <span class="number">2</span></div><div class="line">    stride: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Ip1 Layer</li>
</ul>
<p>将C<em>H</em>W转换成1D feature vector，即800-&gt;500.</p>
<p>(batch_size，50，4，4) -&gt; (batch_size，500)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义全连接层1=============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"ip1"</span></div><div class="line">  type: <span class="string">"InnerProduct"</span> <span class="comment">#该层的类型为全连接层</span></div><div class="line">  bottom: <span class="string">"pool2"</span></div><div class="line">  top: <span class="string">"ip1"</span></div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">1</span></div><div class="line">  &#125;</div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">  inner_product_param &#123;</div><div class="line">    num_output: <span class="number">500</span> <span class="comment">#有500个输出通道</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"xavier"</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Relu1 Layer</li>
</ul>
<p>(batch_size，500) -&gt; (batch_size，500)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义ReLU1层=============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"relu1"</span></div><div class="line">  type: <span class="string">"ReLU"</span></div><div class="line">  bottom: <span class="string">"ip1"</span></div><div class="line">  top: <span class="string">"ip1"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>ReLU是一个元素操作，因此可以使用原地操作（in-place operations）用于节省空间。其实就是top与bottom的名字相同。当然其他的层不能使用重复的blob名称。</p>
<ul>
<li>Ip2 Layer</li>
</ul>
<p>(batch_size，500) -&gt; (batch_size，10)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义全连接层2============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"ip2"</span></div><div class="line">  type: <span class="string">"InnerProduct"</span></div><div class="line">  bottom: <span class="string">"ip1"</span></div><div class="line">  top: <span class="string">"ip2"</span></div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">1</span></div><div class="line">  &#125;</div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">  inner_product_param &#123;</div><div class="line">    num_output: <span class="number">10</span>          <span class="comment">#10个输出数据，对应0-9十个数字</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"xavier"</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Loss Layer</li>
</ul>
<p>(batch_size，10) -&gt;  (batch_size，10)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#==============定义损失函数层============================</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"loss"</span></div><div class="line">  type: <span class="string">"SoftmaxWithLoss"</span></div><div class="line">  bottom: <span class="string">"ip2"</span></div><div class="line">  bottom: <span class="string">"label"</span></div><div class="line">  top: <span class="string">"loss"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>Accuracy准确率层</li>
</ul>
<p>这一层是用于在测试中返回准确率使用的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"accuracy"</span></div><div class="line">  type: <span class="string">"Accuracy"</span></div><div class="line">  bottom: <span class="string">"ip2"</span></div><div class="line">  bottom: <span class="string">"label"</span></div><div class="line">  top: <span class="string">"accuracy"</span></div><div class="line">  include &#123;</div><div class="line">    phase: TEST</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>与loss相似，但要注明<code>phase: TEST</code></p>
<h4 id="Solver"><a href="#Solver" class="headerlink" title="Solver"></a>Solver</h4><p>上面的prototxt主要定义模型，而solver主要定义模型的参数更新与求解方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 制定训练和测试模型</span></div><div class="line">net: <span class="string">"your/prototxt.prototxt"</span></div><div class="line"><span class="comment"># 指定多少测试集参与向前计算，这里的测试batch size=100，所以100次可使用完全部10000张测试集.</span></div><div class="line">test_iter:<span class="number">100</span></div><div class="line"><span class="comment"># 每训练test_interval次迭代进行一次训练.</span></div><div class="line">test_interval： <span class="number">500</span></div><div class="line"><span class="comment"># 基础学习率.</span></div><div class="line">base_lr: <span class="number">0.01</span></div><div class="line"><span class="comment">#动量</span></div><div class="line">momentum: <span class="number">0.9</span></div><div class="line"><span class="comment">#权重衰减</span></div><div class="line">weight_decay: <span class="number">0.0005</span></div><div class="line"><span class="comment"># 学习策略</span></div><div class="line"><span class="comment">#http://stackoverflow.com/questions/30033096/what-is-lr-policy-in-caffe</span></div><div class="line">lr_policy:<span class="string">"inv"</span><span class="comment">#inv: return base_lr * (1 + gamma * iter) ^ (- power)</span></div><div class="line">gamma: <span class="number">0.0001</span></div><div class="line">power: <span class="number">0.75</span></div><div class="line"><span class="comment"># 每隔多少次迭代展现结果</span></div><div class="line">display: <span class="number">100</span></div><div class="line"><span class="comment"># 最大迭代数量</span></div><div class="line">max_iter: <span class="number">10000</span></div><div class="line"><span class="comment"># 每隔多少次迭代保存临时模型</span></div><div class="line">snapshot: <span class="number">5000</span></div><div class="line"><span class="comment">#模型前缀</span></div><div class="line"><span class="comment">#不加前缀为iter_迭代次数.caffemodel</span></div><div class="line"><span class="comment">#加之后为lenet_iter_迭代次数.caffemodel</span></div><div class="line">snapshot_prefix: <span class="string">"examples/minst/lenet"</span></div><div class="line"><span class="comment">#设置求解其类型，CPU or GPU</span></div><div class="line">solver_model：gpu</div></pre></td></tr></table></figure>
<hr>
<h6 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h6><p><a href="http://blog.csdn.net/yan_joy/article/details/53083208" target="_blank" rel="external">caffe学习（9）LeNet在Caffe上的使用</a></p>
<p><a href="http://www.cnblogs.com/xiaopanlyu/p/5793280.html" target="_blank" rel="external">Chapter 4 深入理解Caffe MNIST DEMO中的LeNet网络模型</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <p class="site-author-name" itemprop="name">半城秋雨半城月</p>
            <p class="site-description motion-element" itemprop="description"></p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">半城秋雨半城月</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
